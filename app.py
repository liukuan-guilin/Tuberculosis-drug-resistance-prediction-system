#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è‚ºç»“æ ¸è€è¯æ€§é¢„æµ‹Webåº”ç”¨
åŸºäºéšæœºæ£®æ—æ¨¡å‹çš„å®æ—¶é¢„æµ‹ç³»ç»Ÿ
"""

import os
import pickle
import joblib
import numpy as np
import pandas as pd
import shap
from flask import Flask, render_template, request, jsonify
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

app = Flask(__name__)

# å…¨å±€å˜é‡
model = None
scaler = None
feature_names = None
feature_importance = None
explainer = None

def load_models():
    """åŠ è½½æ¨¡å‹å’Œç›¸å…³æ–‡ä»¶"""
    global model, scaler, feature_names, feature_importance, explainer
    
    try:
        # åŠ è½½æ¨¡å‹
        model = joblib.load('top1_model_éšæœºæ£®æ—.pkl')
        print("âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # åŠ è½½æ ‡å‡†åŒ–å™¨
        scaler = joblib.load('scaler.pkl')
        print("âœ“ æ ‡å‡†åŒ–å™¨åŠ è½½æˆåŠŸ")
        
        # åŠ è½½ç‰¹å¾åç§°
        feature_names = joblib.load('feature_names.pkl')
        print("âœ“ ç‰¹å¾åç§°åŠ è½½æˆåŠŸ")
        
        # åŠ è½½ç‰¹å¾é‡è¦æ€§
        feature_importance = pd.read_csv('shap_feature_importance_top1_éšæœºæ£®æ—.csv')
        print("âœ“ ç‰¹å¾é‡è¦æ€§åŠ è½½æˆåŠŸ")
        
        # åˆå§‹åŒ–SHAPè§£é‡Šå™¨
        explainer = shap.TreeExplainer(model)
        print("âœ“ SHAPè§£é‡Šå™¨åˆå§‹åŒ–æˆåŠŸ")
        
        return True
    except Exception as e:
        print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False

def get_feature_mapping():
    """è·å–ç‰¹å¾æ˜ å°„å­—å…¸"""
    return {
        'Interval from Symptom Onset to Diagnosis (days)': {
            'name': 'ç—‡çŠ¶å‡ºç°åˆ°è¯Šæ–­é—´éš”å¤©æ•°',
            'name_en': 'Interval from Symptom Onset to Diagnosis (days)',
            'type': 'number',
            'min': 0,
            'max': 365,
            'default': 30
        },
        'Smoking History 0=No 1=Yes': {
            'name': 'å¸çƒŸå²',
            'name_en': 'Smoking History',
            'type': 'select',
            'options': [('0', 'å¦'), ('1', 'æ˜¯')],
            'options_en': [('0', 'No'), ('1', 'Yes')],
            'default': '0'
        },
        'Tuberculosis Treatment History 1=New Case 2=Previously treated': {
            'name': 'ç»“æ ¸ç—…æ²»ç–—å²',
            'name_en': 'Tuberculosis Treatment History',
            'type': 'select',
            'options': [('1', 'æ–°å‘ç—…ä¾‹'), ('2', 'æ—¢å¾€æ²»ç–—')],
            'options_en': [('1', 'New Case'), ('2', 'Previously treated')],
            'default': '1'
        },
        'Treatment Adherence 0=Poor 1=Good': {
            'name': 'æ²»ç–—ä¾ä»æ€§',
            'name_en': 'Treatment Adherence',
            'type': 'select',
            'options': [('0', 'å·®'), ('1', 'å¥½')],
            'options_en': [('0', 'Poor'), ('1', 'Good')],
            'default': '1'
        },
        'Pretreatment smear results 0=Negative 1=1+ 2=2+ 3=3+ 4=4+': {
            'name': 'æ²»ç–—å‰æ¶‚ç‰‡ç»“æœ',
            'name_en': 'Pretreatment Smear Results',
            'type': 'select',
            'options': [('0', 'é˜´æ€§'), ('1', '1+'), ('2', '2+'), ('3', '3+'), ('4', '4+')],
            'options_en': [('0', 'Negative'), ('1', '1+'), ('2', '2+'), ('3', '3+'), ('4', '4+')],
            'default': '0'
        },
        'Monocytes (10^9/L)': {
            'name': 'å•æ ¸ç»†èƒè®¡æ•° (10^9/L)',
            'name_en': 'Monocytes (10^9/L)',
            'type': 'number',
            'min': 0,
            'max': 2.0,
            'step': 0.01,
            'default': 0.5
        },
        'Hemoglobin (HGB, g/L)': {
            'name': 'è¡€çº¢è›‹ç™½ (g/L)',
            'name_en': 'Hemoglobin (g/L)',
            'type': 'number',
            'min': 50,
            'max': 200,
            'default': 120
        },
        'FPG (mmol/L)': {
            'name': 'ç©ºè…¹è¡€ç³– (mmol/L)',
            'name_en': 'FPG (mmol/L)',
            'type': 'number',
            'min': 3.0,
            'max': 20.0,
            'step': 0.1,
            'default': 5.5
        },
        'Pulmonary Micronodules 0=No 1=Yes': {
            'name': 'è‚ºå¾®ç»“èŠ‚',
            'name_en': 'Pulmonary Micronodules',
            'type': 'select',
            'options': [('0', 'å¦'), ('1', 'æ˜¯')],
            'options_en': [('0', 'No'), ('1', 'Yes')],
            'default': '0'
        },
        'Pulmonary Cavitation 0=No 1=Yes': {
            'name': 'è‚ºç©ºæ´',
            'name_en': 'Pulmonary Cavitation',
            'type': 'select',
            'options': [('0', 'å¦'), ('1', 'æ˜¯')],
            'options_en': [('0', 'No'), ('1', 'Yes')],
            'default': '0'
        },
        'Pulmonary Consolidation 0=No 1=Yes': {
            'name': 'è‚ºå®å˜',
            'name_en': 'Pulmonary Consolidation',
            'type': 'select',
            'options': [('0', 'å¦'), ('1', 'æ˜¯')],
            'options_en': [('0', 'No'), ('1', 'Yes')],
            'default': '0'
        },
        'PNI': {
            'name': 'é¢„åè¥å…»æŒ‡æ•° (PNI)',
            'name_en': 'PNI',
            'type': 'number',
            'min': 20,
            'max': 70,
            'step': 0.1,
            'default': 45
        }
    }

@app.route('/')
def index():
    """ä¸»é¡µ"""
    feature_mapping = get_feature_mapping()
    return render_template('index.html', feature_mapping=feature_mapping)

@app.route('/predict', methods=['POST'])
def predict():
    """é¢„æµ‹æ¥å£"""
    try:
        # è·å–è¾“å…¥æ•°æ®
        input_data = request.json
        language = input_data.get('language', 'zh')  # è·å–è¯­è¨€å‚æ•°
        
        # æ„å»ºç‰¹å¾å‘é‡
        feature_vector = []
        for feature_name in feature_names:
            if feature_name in input_data:
                feature_vector.append(float(input_data[feature_name]))
            else:
                # ä½¿ç”¨é»˜è®¤å€¼æˆ–0
                feature_vector.append(0.0)
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶reshape
        X = np.array(feature_vector).reshape(1, -1)
        
        # æ ‡å‡†åŒ–
        X_scaled = scaler.transform(X)
        
        # é¢„æµ‹
        prediction = model.predict(X_scaled)[0]
        probability = model.predict_proba(X_scaled)[0]
        
        # è®¡ç®—SHAPå€¼
        shap_values = explainer.shap_values(X_scaled)
        
        # å¤„ç†SHAPå€¼çš„ä¸åŒæ ¼å¼
        if isinstance(shap_values, list):
            # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå–è€è¯ç±»åˆ«çš„SHAPå€¼
            shap_values = shap_values[1]
        elif len(shap_values.shape) == 3:
            # å¦‚æœæ˜¯ä¸‰ç»´æ•°ç»„ (n_samples, n_features, n_classes)ï¼Œå–è€è¯ç±»åˆ«çš„SHAPå€¼
            shap_values = shap_values[:, :, 1]
        
        # ç¡®ä¿shap_valuesæ˜¯äºŒç»´æ•°ç»„ (n_samples, n_features)
        if len(shap_values.shape) == 1:
            shap_values = shap_values.reshape(1, -1)
        
        # è·å–ç‰¹å¾è´¡çŒ®
        feature_contributions = []
        for i, feature_name in enumerate(feature_names):
            if i < shap_values.shape[1]:
                shap_val = shap_values[0, i]
                # æ ¹æ®è¯­è¨€è·å–ç‰¹å¾å
                feature_mapping = get_feature_mapping()
                if language == 'en':
                    display_name = feature_mapping.get(feature_name, {}).get('name_en', feature_name)
                else:
                    display_name = feature_mapping.get(feature_name, {}).get('name', feature_name)
                
                feature_contributions.append({
                    'feature': display_name,
                    'value': float(X[0][i]),
                    'shap_value': float(shap_val),
                    'contribution': abs(float(shap_val))
                })
        
        # æŒ‰è´¡çŒ®åº¦æ’åº
        feature_contributions.sort(key=lambda x: x['contribution'], reverse=True)
        
        # å¤„ç†expected_value
        if isinstance(explainer.expected_value, np.ndarray):
            if len(explainer.expected_value) > 1:
                base_value = float(explainer.expected_value[1])
            else:
                base_value = float(explainer.expected_value[0])
        else:
            base_value = float(explainer.expected_value)
        
        # æ ¹æ®è¯­è¨€è®¾ç½®é£é™©ç­‰çº§æ–‡æœ¬
        if language == 'en':
            risk_level = 'High Risk' if prediction == 1 else 'Low Risk'
        else:
            risk_level = 'é«˜é£é™©' if prediction == 1 else 'ä½é£é™©'
        
        # è¿”å›ç»“æœ
        result = {
            'prediction': int(prediction),
            'probability': {
                'sensitive': float(probability[0]),
                'resistant': float(probability[1])
            },
            'risk_level': risk_level,
            'top_features': feature_contributions[:8],  # è¿”å›å‰8ä¸ªé‡è¦ç‰¹å¾
            'base_value': base_value
        }
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({'error': f'é¢„æµ‹å¤±è´¥: {str(e)}'}), 500

@app.route('/feature_importance')
def get_feature_importance():
    """è·å–ç‰¹å¾é‡è¦æ€§"""
    try:
        # è·å–è¯­è¨€å‚æ•°
        language = request.args.get('lang', 'zh')
        
        # ç‰¹å¾åç§°æ˜ å°„ï¼ˆä»ç®€åŒ–åç§°åˆ°å®Œæ•´åç§°ï¼‰
        feature_name_mapping = {
            'Symptom_Onset_Days': 'Interval from Symptom Onset to Diagnosis (days)',
            'TB_Treatment_History': 'Tuberculosis Treatment History 1=New Case 2=Previously treated',
            'Treatment_Adherence': 'Treatment Adherence 0=Poor 1=Good',
            'Pulmonary_Cavitation': 'Pulmonary Cavitation 0=No 1=Yes',
            'Smoking_History': 'Smoking History 0=No 1=Yes',
            'Pretreatment_Smear': 'Pretreatment smear results 0=Negative 1=1+ 2=2+ 3=3+ 4=4+',
            'Pulmonary_Micronodules': 'Pulmonary Micronodules 0=No 1=Yes',
            'Pulmonary_Consolidation': 'Pulmonary Consolidation 0=No 1=Yes',
            'FPG': 'FPG (mmol/L)',
            'Hemoglobin': 'Hemoglobin (HGB, g/L)',
            'PNI': 'PNI',
            'Monocytes': 'Monocytes (10^9/L)'
        }
        
        # ä¸­æ–‡ç‰¹å¾åç§°æ˜ å°„
        chinese_feature_mapping = {
            'Symptom_Onset_Days': 'ç—‡çŠ¶å‡ºç°åˆ°è¯Šæ–­é—´éš”å¤©æ•°',
            'TB_Treatment_History': 'ç»“æ ¸ç—…æ²»ç–—å²',
            'Treatment_Adherence': 'æ²»ç–—ä¾ä»æ€§',
            'Pulmonary_Cavitation': 'è‚ºç©ºæ´',
            'Smoking_History': 'å¸çƒŸå²',
            'Pretreatment_Smear': 'æ²»ç–—å‰æ¶‚ç‰‡ç»“æœ',
            'Pulmonary_Micronodules': 'è‚ºå¾®ç»“èŠ‚',
            'Pulmonary_Consolidation': 'è‚ºå®å˜',
            'FPG': 'ç©ºè…¹è¡€ç³–',
            'Hemoglobin': 'è¡€çº¢è›‹ç™½',
            'PNI': 'é¢„åè¥å…»æŒ‡æ•°',
            'Monocytes': 'å•æ ¸ç»†èƒ'
        }
        
        # è½¬æ¢ä¸ºå‰ç«¯éœ€è¦çš„æ ¼å¼
        importance_data = []
        
        for _, row in feature_importance.iterrows():
            # è·å–ç®€åŒ–çš„ç‰¹å¾å
            feature_key = row['Feature']
            
            # æ ¹æ®è¯­è¨€é€‰æ‹©æ˜¾ç¤ºåç§°
            if language == 'en':
                display_name = feature_name_mapping.get(feature_key, row['Chinese_Feature'])
            else:
                display_name = chinese_feature_mapping.get(feature_key, feature_key)
            
            importance_data.append({
                'feature': display_name,
                'importance': float(row['SHAP_Importance'])
            })
        
        return jsonify(importance_data)
    except Exception as e:
        return jsonify({'error': f'è·å–ç‰¹å¾é‡è¦æ€§å¤±è´¥: {str(e)}'}), 500

if __name__ == '__main__':
    print("æ­£åœ¨å¯åŠ¨è‚ºç»“æ ¸è€è¯æ€§é¢„æµ‹ç³»ç»Ÿ...")
    
    if load_models():
        print("\n" + "="*50)
        print("ğŸ¥ è‚ºç»“æ ¸è€è¯æ€§é¢„æµ‹ç³»ç»Ÿ")
        print("ğŸ“Š åŸºäºéšæœºæ£®æ—æ¨¡å‹")
        print("ğŸ”¬ é›†æˆSHAPå¯è§£é‡Šæ€§åˆ†æ")
        print("="*50)
        print("\nç³»ç»Ÿå¯åŠ¨æˆåŠŸï¼")
        print("è®¿é—®åœ°å€: http://localhost:5000")
        print("æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
        print("\n" + "="*50)
        
        app.run(debug=True, host='0.0.0.0', port=5000)
    else:
        print("âŒ ç³»ç»Ÿå¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶")